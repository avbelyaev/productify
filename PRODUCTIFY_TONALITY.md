# Продуктивизация модели

## Step 1 (baseline)

_примерное время: 3-5 часов_ 

_теги: API, HTTP (TCP/IP, методы, статусы, header'ы), терхзвенная архитектура, REST HTTP API, endpoint (controller), cURL, XHR_

Я, как пользователь, могу зайти в приложение и ввести текст в единственное текстовое поле.
После нажатия кнопки "Analyze", в интерфейсе я вижу значение тональности введенного текста, либо сообщение об ошибке в остальных случаях.

Ожидаемый результат:
- фронтенд с текстовым полем, кнопкой и показом результата классификации
- бекенд, обрабатывающий запросы от фронта
- классификатор, выполняющий саму логику классификации
- все работает локально в браузере

## Классификатор

Разработку будем вести снизу вверх. См подробнее [внизу](#виды-разработки).

Начинаем разработку с самого нижнего слоя. У нас в самом низу - классификатор.

Надо выделить интерфейс классификатора, он же API. Подробнее см [внизу](#api)

Если я сторонний разработчик, то мне не важно, как внутри работает твоя модель и уж тем более я не знаю,
как ее пиклить и какие нумпаевские методы дергать. Поэтому я бы хотел импользовать ее как билиотеку, котрая предосталяла бы API типа такого:
```python
t = TonalityAnalyzer()
tone1 = t.analyzeTone(text='Ужасно смешной фильм', lang='ru')
tone2 = t.analyzeTone(text='the movie was fcking awesome!', lang='en')
```

Но! т.к. модельку делаем мы сами, то мы знаем как ее дергать, поэтому такую обертку над моделькой можно сейчас не городить.
Главное, чтобы она делала свою работу (принимала строку и возвращала результат классификации), а уж в каком виде - сейчас не важно.



## Бекенд

Бекенд отвечает за бизнес-логику приложения и связывает пользовательскую часть с классификатором.

Предлагается реализовать API со следующим контрактом:

- Определение тональности переданного текста 
    - POST `/api/tonality/analyze` - это называют **endpoint** (или контроллер) - то есть "конечная точка" соединения, т.е. место, куда приходит запрос от клиента
    - Принимает json вида:
```json
{
  "text": <строка, текст для анализа>
}
```
    - Тональность опеределена успешно: 200 OK и json вида: 
```json
{
  "tone": <float, число обозначающее тональность>
}
```

Мы хотим спроектировать API. API это вещь абстрактная, т.е. это просто о том, как с объектом взаимодействовать, но мысли никто
читать не умеет, а объект, с которым мы хотим работать находится где-то на сервере в интернете, так что нам нужно что-то физическое, 
с помощью чего можно организовать это взаимодействие. В данном случае самая физическая вещь, что у нас есть - протокол HTTP - hypertext transfer protocol. 

Про то, как работает HTTP смотри [внизу](#http)
 
- Помнишь, мы в классификаторе хотели сделать удобное API над моделькой? 
    - Так вот, там мы реалзиовывали API с помощью языка python, т.к. объект, с которым мы хотели работатьт был питоновским объектом ( в терминах ООП).
    - получаем python API
- Сейчас у нас "объект" находится где-то на сервере в недрах интернета 
    - И его API надо реализовывать так, чтобы мы смогли с ним работать через интренет
    - получаем HTTP API
    - HTTP API обычно отвечает "требованиям" REST. Про REST см [внизу](#rest)

Бекенд должен предоставлять описанный выше **REST HTTP API** и тогда с ним можно будет взаимодейстовать с помощь curl, бразуера, python-requests и здравого смысла.

### Задания 
0. Реализовать описанный выше HTTP API на Flask'е
1. Прежде чем делать фронт, надо понять что бек работает. 
    - Как запустить бекенд без пайчарма?
2. Как локально дернуть API curl’ом?
    - раньше мы делали что-то типа `curl --data ... localhost:8080/do/smth` и передавали заголовки и сам json 
3. Убедиться что запросы приходящие на бекенд отображаются в stdout 
    - иначе будет сложно отлаживать работу, не понимая, дошел запрос до бека или потерялся в дебрях сетей AWS
4. _доп_ На каждый приходящий запрос писать в лог (для начала `print`), кто его отправил, т.е. User agent отправителя
    - можно будет увидеть, что вот пришел запрос от хрома, вот от curl'а, а вот - от веб-краулера
  
### Контрольные вопросы
1. В чем отличие HTTP методов POST, PUT, HEAD?
2. Каким заголовком мы можем "попросить" сервер вернуть нам в качестве ответа НЕ json, а, например, xml или html?
3. Набросать HTTP API интернет магазина (просмотр товаров, добавление в корзину, оформление заказа) - хотя бы 3-4 ендпоинта
4. Можно ли удалять документы (пусть документ == пользователь) выполняя GET-запрос `/api/users/<id>`?
5. HTTP не хранит состояние (он не знает что перед запросом Y был запрос X) - как в таком случае сказать серверу, что мы уже встрчались (и логинились) - иначе он каждый раз будет простить нас залогиниться?

  
  
## Фронтенд

UI выглядит максимально просто:
- текстовое поле для ввода ссобщения
- кнопка "Analyze", по нажатию которой текст отправляется на анализ тональности
- блок, показывающий тональность введенного сообщения (например, числом от 0 до 1) 

Технически максмально прост:
- файл с разметкой и описанными выше тремя ключевыми элементами страницы
- файл со стилями, чтобы смотрелось красиво 
    - предложил бы вообще забить на CSS в начале, т.к. на CSS может уйти времени больше чем на весь этот tutorial
- файл с js-кодом, отвечающий за отправку запроса, получение ответа и отображение ответа на странице. 
    - чтобы отправить запрос, надо считать введенный в текстовое поле текст, обернуть его в json и отправить (с соблюдением всех заголвоков и всего, что мы отлаживали curl'ом)
    - в ответе надо принять json, расправсить его поле `tone` и вывести значение в какой-либо элемент на странице (google "add text to div")

### Задания
0. Реализовать фронтенд
1. Реализовать асинхронную отправку запросов
    - веб работает аснихронно и запрос тоже должен быть асинхронным (синхронный запрос выполняется синхронно, т.е. блокрирует выполнение остальных команд, пока
  не будет завершена текущая. Сеть ненадежна и ответ может не прийти никогда - тогда клиент навечно зависнет). 
    - самый простой способ - XHR - см [здесь](https://learn.javascript.ru/xmlhttprequest)
2. убедится, что запросы доходят до бека
    - они должны уходить на host:port где разернут бекенд
    - запросы из браузера так же видны во вкладке "networks" в dev tools (chrome F12)
3. Настройка CORS. 
    - cURL отправляет запросы AS IS, "как есть". Браузер работает более деликатно
    - Браузер, прежде чем что-либо куда-либо слать, сначала спросит, готов ли сервер принять такой запрос. 
    - Такой предварительный запрос называется preflight request. 
    - Надо уметь его принять на беке и верно ответить, иначе браузер не будет выполнять "основной запрос"
    - Ошибки CORS как правило заметны в dev tools (вкладки "network" и "console"), chrome F12
4. наконец, запустить фронтенд, чтобы его можно было открыть в браузере по адресу `http://localhost` 
    - мы раздавали фронт с помощью встроенного питоновского веб-сервера (`python3 -m http.server ...`)
    - настроить правильный порт для разадачи фронтенда
5. _доп_ сделай собственную красивую кнопку с помощью `<div>`
    - Посмотри свойства `hover` и `active` html-элемента и почитай про свойство `onclick=` 
 

### Контрольные вопросы
0. В URL укзаано, что мы идем на `https://google.com`. Но этот путь указывает не на конкретную страницу, а тупо на хост.
    - какой файл сервер по умолчанию будет искать, ведь страничку гугла мы все-таки увидим?
1. Какой порт используется протоколом HTTP по умолчанию? 
    - какой у HTTPS? какой используется протоколом SSH?
2. Какой HTTP статус говорит о том, что документ не найден?
    - за что отвечают статусы 2хх? 3хх? 4хх? 5хх?
3. Можно ли ответить статусом 666 на запрос, например, создания пользователя? 
4. Как почистить куки в хроме?
5. Как удалить дурацкий баннер на Pinterest, который закрывает экран, если ты не залогинен?
    - баннер это точно такой же html-элемент как и все что есть на странице. занчит, он подчиняется тем же законам, что и остальные элементы
    - значит, мы можем "работать" с ним через dev tools и можем вырезать его со страницы :)
6. уметь объяснить что значит каждый тег в начале занятия

---





## Step 2 (раздача фронтенда с бекенда)

![o](img/flask-logo.png)

_примерное время: 1 час_ 

_теги: DNS, резолвинг адресов, статика_

в этой серии мы научимся оперировать приложением, как единым целым и запускать одним процессом

Выше мы сделали бейзлайн нашего приложения, или можно сказать MVP - minimal viable product == минимальную рабочую версию.
Она работает локально, но пришло время дать пользователям доступ к ней. Для этого необходимо сделать ряд изменений в базовой версии.

- Как ты помнишь, сейчас фронтенд запускается отдельным процессом с помощью стандартного питоновского веб-сервера. 
Этот веб-сервер разадет все, что находится в текущей директории (в том числе пресловутый index.html), откуда запущен процесс.
- Бекенд запущен как питоновское приложение
 
Но, как ты понимаешь, это все-таки 2 разных процесса - один раздает фронтенд, другой крутит бекенд.

Действия пользователя:
- Я, как пользователь, открываю твое приложение по адресу `http://maryblack.rocks`
    - Я нахожусь в мск
    - а сервер с приложением крутится где-то на западном побережье америки
- мой браузер делает запрос на хост 1.2.3.4 и порт :80 за стартовой страничкой index.html
    - за то, как `http://maryblack.rocks` резловится в `http://1.2.3.4` отвечает DNS - я тебе о нем говорил. Можно считать, что это map{hostname -> ip}: `DNS["marybcloak"]="1.2.3.4"`
    - на сервере мне отвечает тот питоновский процесс, который сидит на порту :80 - с ним я общаться могу.
    - у меня в браузере в москве открылась страничка с твоим приложением (то есть мне прилетели мои "копии" html,css,js и отрендерили приложение)
    - я ввожу текст и нажимаю кнопку "Analyze". Внимание, вопрос, куда уйдет запрос? 
        - На какой хост:порт? ведь мне нужно достучаться до единственного конкретного сервера в америке!
        - кто его на том хосту:порту примет? подумай, как оно может быть устроено
        - ответы на оба вопроса - чуть ниже
          
вот как работает DNS на картинке по порядку: 

![o](img/dns.jpg)
          
#### на какой хост:порт уйдет запрос?
- существуют _абсолютные_ и _относительные_ адреса - ты это, думаю, знаешь. 
    - абcолютный адрес: `https://maryblack.rocks/models/tonality/index.html?foo=bar`
    - отнсительный: `/foo/bar/baz`. говоря об относительной адресации всегда надо понимать _относительно чего_ идет адресация
    - запрос можно сделать *только собрав полный (абсолютный) URL* (ведь нам нужно получить ip-адрес по hostname'у от DNS, но hostname'а в отнсительном адресе нет)
- так вот, в запросах мы раньше явно указывали полный абсолютный URL бека: `http://localhost:5000/api/tonality/analyze` 
- но мы ведь хотим, чтобы со страницы, открытой у меня на компе в мск запрос ушел на сервер в америку, но мы 
    - не всегда знаем адрес сервера (мы не знаем где в конце концов будет крутиться наша страничка, если это огромный сайт/портал типа гугла или Я)
    - мы не хотим хардкодить этот адрес: представь что у нас на странице 100 кнопок - тогда придется 100 раз писать на копках адреса типа `http://foo.com/api/x`, `http://foo.com/api/y` и тд
- умные люди (разработчики браузеров) решили эту проблему конвенионально:
    - если в запросе указан относительный URL (см выше), то он будет рещолвиться *относительно текущего сайта*
    - то есть запрос `/new_dir/index.php?r=blah` выполненный со страницы `http://www.foo.com/bar.php`
    - будет зарезолвлен в `http://www.foo.com/new_dir/index.php?r=blah` (т.е. относительно текущего сайта `foo.com`)
    - а конпки, как ты понимаешь, и знать не знают полные URL - на каждой из них написано лишь `/api/x`, `/api/y`, `api/z`
- так вот, в нашем случае запрос `/api/tonality/analyze` пойдет на `http://maryblack.rocks/api/tonality/analyze` и нам при этом не надо указывать ни хост, ни порт.


#### кто его на том хосту:порту примет?
- по-правильному решается это с помощью проксирования запросов (тот самый Nginx)
- запросы так же приходят на один сервер (он и раздает *статику* - статический, редко меняющийся контент, и обслуживает вызовы к API)
- но дальше в зависимости, от типа запроса, в ответ отдается либо статика (html/css/js, картинки, видосики), либо запрос перенаправляется на бекенд. 
    - самое интуитивное правило роутинга: если запрос начианется на `/api/**`, то мы его проксируем, например:
        - Запрос `http://maryblack.rocks/models/tonality` вернет index.html
        - Запрос `http://marycloak.rocks/api/models/tonality` будет запроскирован на бекенд и ответит на него сам бекенд
        
Проксировать умеют все сервера (Apache, Nginx и т.д.), но возиться с прокси - это не то, чего мы хотим (хотя можем, если интересно :) ). 

Поэтому мы можем пойти в другую сторону: сделать так, чтобы наш бекенд одновременно 
- раздавал статику (наши 3 файлика)
- раздавал HTTP API
- занимал при этом только 1 порт

Веб-серверы, коим является и Flask, из коробки умеют раздавать статику. Это решается, как правило, конвенционально: 
- встроенный `pythom -m http.server` раздается текущую директорию
- Nginx раздает папку `./var/nginx/html`
- Django рдздает папку, например, `./assets`
- Flask раздает папку ??? (Я не знаю, какую именно директорию он раздает)

если к этому моменту у тебя возникла путаница в "серверной" терминологии, то [внизу](#djangи-flaskи-сервера) я кратко попытался прояснить это.

### Задание
1. Понять (из доков), что нужно для раздачи статики FLask'ом
    - скорее всгео это какой-то ендпоинт (контроллер), который скажет flask'у, что теперь он должен раздавать статику
        - у нас есть ендпоинт `/api/analyze` для бизнес логики, а будет еще один - для раздачи статики
    - гуглится в стиле "flask host static resources" или "flask serve static content"
2. Орагнизовать проект так, чтобы фронтенд был собран в той папке, которую будет раздавать flask 
3. запутсить *только бекенд* и убедиться, что фронтенд раздается с него
    - проверить, что приложение доступно из браузера
    - указать (или убедиться, что указан) правильный адрес для запроса по кнопке "Analyze" и запрос отрабатывает

### Контрольные вопросы
1. уметь объяснить, что значит каждый тег в начале занятия

---





## Step 3 (деплой на AWS)

![o](img/aws_logo_1.png)

_примерное время: 1 час_ 

_теги: AWS, deploy_

К этому моменту наше приложение уже работает как единое целое и не зависит от места расположения сервера (в коде не хардкодятся localhost'ы).
Пришло время открыть его всему миру!

Давным давно Amazon столкнулся с тем, что его информационная система была слишком слаба для обслуживания всех его складов, доставщиков, покупаетелй, продавцов и прочей логистики.
Они отрефакторили свою систему: теперь команды брали чуть-чуть мощностей Amazon'овского парка машин и работали на них. 
И тут они поняли, что получлось нечто большее и "продали" идею Безосу как новый бизнес.

Суть была проста: последнее, чем стартапам, малому и среднему-неайтишному бизнесу (и тебе) хочется заниматься - это е*аться с желеязяками, настраивать сеть и поднимать линуксы.
Компании хотят максимально быстро дать людям продукт, а не нарезать виртуалки. И за нарезку виртуалок, настройку сетей и железа стал отвечать сам Amazon. Так появился AWS.
Концепцию назвали **Infrastructure-as-a-Service (IaaS)**, то есть "инфраструктура в аренду".

Первым продуктом стали виртуальные машины (обычные linux ubunt'ы) - Amazon EC2 (Elastic Compute Cloud) - то есть практически первое "вычислительное облако". 
Elastic - значит, что оно может "растягиваться под потребности", лишь бы были деньги.

Затем появлись Google Cloud, Microsoft Azure. Потом появлись российкие копии типа Mailru Cloud Solutions и Я.облако, 
но было уже поздно, т.к. Amazon вошел в раш и начал делать все "as-a-Service", то есть БД-as-a-service, hadoop-as-a-service, DNS-as-a-service и тд.

![o](img/aws.png)

С тех пор компании не владеют железом, а арендуют его у Amazon (и строят большие сложные, но абсолютно виртуальные системы) и уже инженеры AWS е*тся с железяками. 
А самый обльшой и тербовательный клиент AWS - Netflix со своими премьерами stranger things. [здесь](https://theogm.com/2017/09/10/are-you-aligned-with-the-fastest-growing-cloud-platform-on-the-planet/) можно чуть подробнее почитать об этом


Так вот, мы тоже не хотим копаться в железе, а хотим арендовать виртуалку (виртуальный сервер, кусок физической машины) в AWS EC2.
Такую машину называют инстансом (EC2 instance). Как ее получить:
- зарегистрироваться во free-tier AWS
- найти среди многочисленных сервисов нужный нам EC2
- EC2 имеет контрольную панель на которй отображаются все имеющиеся у тебя машины
    - instance type - тип машины (кол-во ядер, RAM, сеть и тд)
    - zone - регион, в которм запущена машина
    - public/private DNS - DNS внутри кластера машин, то есть это о том, как достучаться снаружи/извне до твоей тачки
        - как ты помнишь, достучаться можно по hostname'у http://ec2-52-91-34-110.compute-1.amazonaws.com
        - а можно напрямую по IP-адресу `52.91.34.110`, в который резолвится этот hostname

![o](img/ec2.png)

По кнопке "Launch instance" мы заказываем новую машину. Во free-tier'е у тебя может быть максимум одна машина на 1 ядро и 1Гб RAM и 10Гб жесткий диск.
Надо пройти через несколько шагов, чтобы создать машину
- выбрать ОС (лучше всего выбирать ubuntu)
- выбрать тип машины (t2.micro), память, что-то еще. как правило, в каждом пунтке бесплатная опция помечена зеленым шильдиком "free tier"
- сгенерировать пару ключей доступа (на машину сложат публичный ключ, тебе дадут скачать приватный ключ)
- после этого машина запустится и будет доступна по SSH с выданным тебе ключом.
    - тонкий момент: чтобы зайти по SSH, ты указываешь user@host ("user at host"). в данном случае user - `ubuntu`

По умолчанию ради безопасности на машине открыт только порт 22 для SSH. Это значит, что до машины кроме как по SSH достучаться не получится.
Чтобы до машины можно было достучаться другими способами, надо настроить "security groups":
- в консоли EC2 в разделе security groups надо создать "правило" фильтрации трафика
    - правила применяются ко входящему/исходящему трафику: inboud/outbound rules
    - надо создать правило, которое откроет нужный тебе порт (надеюсь, к этому моменты ты уже знакома с портами)
    - после этого, надо применить созданное правило к машине: это делается правым кликом по инстансу (по крайней мере, на момент написания статьи это делалрсь именно так)
    - google "ec2 security groups for web server" 

Процесс выкладки приложения в прод называется **деплоем** (deploy, deployment, развертывание, "накатываем в пятницу"). Часто коверкуют до уродского "раскладка", но суть не меняется:
до деплоя приложение работало локально, а теперь работает на каком-то стенде (test, stage, preprod, prod и тд). 

Если с приложением проблемы, приложение откаывают, т.е. делают **роллбек** (rollback, rollout, откат).
Штатное обновление приложения - редеплой.

### Задание
0. создать EC2-инстанс
1. задеплоить на него приложение
    - для этого, разумеется, надо как-то доставить проект на этот сервер
2. создать security group, который бы позволил достучаться до приложения
    - поскольку security group это "о портах", то надо согласовать порты приложения и порты, которые ты настраиваешь в security group
    - применить security group к инстансу
3. убедиться, что приложение доступно всему миру!
    - лучше всего проверять в режиме инкогнито в браузере, чтобы не было проблем с кешами и прочими настройками браузера в обычном режиме
        - не забывай про dev tools
    - можно проверить открыв, как хостнейм, так и напрямую IP-адрес в хроме.
    - убедиться, что бизнес-логика работает (кнопка "Analyze")




---

## Step 3.5 (Minor enhancement)

Этот шаг здесь лишь для того, чтобы показать, как выглядит процесс разработки в общем случае. 
Т.е., тебе захотелось слегка изменить приложение (перекрасить кнопочку на фронте, пофиксить баг на беке, переобучить модельку). 
Попробуй выполнить что-то из этого (думаю, первое или второе проще всего) и заметь, какие действия ты выполняешь в таком случае.

Предложил бы на досуге подумать, как бы ты сделала rollback приложения до предыдущей версии. 




---

## Step 4 (Docker)

![o](img/dockermini.png)

#### Сборка образа

Для сборки image'а используется пошаговая инструкция, описываемая Dockerfile'ом. 

Ты уже заметила парралели с ООП: образ == класс, а контейнер == инстанс (экземпляр, объект) этого класса.
Так вот, на этом параллели не заканчиваются. 

Сборка образа всегда начинается с выбора базового образа. По аналогии с ООП-наследованием,
образы, можно сказать, так же наследуются друг от друга. По аналогии с тем, как в java/scala есть  
самый базовый класс Object, у докера тоже есть такой самый-самый базовый образ - `scratch` ("from scratch" == с нуля).

Такой подход (фактически, наследование) выбран не с проста: в основе того, как докер хранит данные 
внутри образа лежит файловая система Union File System (UnionFS). Проще всего это продемонстрировать на картинке: 

![o](img/unionfs5.png)

Union она потому, что умеет как бы склеивать разные слои создавая единое пространство. Раньше файлики
F1 и F2 лежали в своей файловой системе, а файлики F3 и F4 - в своей, то есть они не видели друг друга. 
Можно сказать что это были 2 физически разных жестких диска. 

После объединения (union) они поместились в общее пространство. То есть теперь они лежат в одной файловой
системе, полученной путем наложения двух других. Теперь они видят друг друга.


Так вот, на этом "уровневом"/слоеном принципе построен докер:

Умные люди (разработчики докера) на основе самого-самого базового образа `FROM scratch` (считай пустого) 
создали образы линуксов - Ubuntu, debian, centos, mint и тд. - то есть они смогли упаковать линукс в Union FS.
То есть поверх базового образа scratch появился слой с линуксом:
- scratch
- ubuntu linux

Так появились первые образы Linux'ов.

Но ведь операционная система нужна для запуска программ - что толку от голого линукса? 
Тогда они взяли за основу уже имеющийся линукс `FROM linux`, например ubuntu, установили в нее python и получили образ питона:
- scratch
- ubuntu linux
- python

Но кому нужен "тупо питон"? Питон нужен для выполнения программ. И тогда ты, взяв за основу, 
образ питона `FROM python3.8` добавляешь в него свою программу, а заодно и библиотеки, зависимости, конфигурацию, и, может быть данные.
Получается такой слоеный пирог (рисую в иерархии ООП)
- scratch
- ubuntu linux
- python3.8
- слой с твоими данными /project/src, /data, /whatever

И вот теперь, когда ты соберешь это воедино, получится цельная картинка:
- вот твоя программа, которую ты можешь запустить питоном
- вот питон, скомпиленный компилятором GCC 
- вот компилятор GCC ("гцц", Gnu C Compiler) идущий в комплекте с убунтой
- и все они видят друг друга (находятся в одном пространстве, одной файловой системе)
- и все это весит условные 100МБ и запускается чуть ли не на калькуляторе!

То есть у тебя есть все, что нужно для запуска программы. 

## Простейший образ

Пришло время собрать свой образ.

Нет ничего проще `echo`. Давай попробуем помесить `echo fuck` в образ? 
Ведь процесс`echo fuck` ничем не отличается от `python3.8 my-awesome-script.py`.

1. Важно помнить следующее: **контйенер жив, пока жив процесс**. 

Как только процесс внутри контейнера останавливается, считается, что крутить контейнер нет смысла. 
То есть если просто вывести 1 раз echo, то ровно это и прозойдет - контейнер создастся, процесс с echo напишет "fuck", 
процесс зваершится, и контйенер будет остановлен.

2. А еще важно помнить, что у Bash'а (shell'а в общем случае) есть альтернативная форма записи:
```bash
echo fuck
# это то же самое, что и
/bin/bash -c "echo fuck"
```

- В первом случае ты выполняешь ее в терминале, где баш работает по умолчанию. 
- Во втором ты явно говоришь выполни команду `echo fuck` интерпретатором `/bin/bash`. 
    - Для чего? Кроме баша есть bin/sh, zsh, ash и даже fish, хоть все они и браться близнецы

Принимая пункт 1 во внимание, можем сделать бесконечный цикл, который бы ругался:
```bash
while true; do echo fuck; sleep 2; done
```

Принимая во вниамение п.2, запишем команду в немного другом виде:
```bash
/bin/bash -c "while true; do echo fuck; sleep 2; done"
```

Итак, цикл бесконченый, значит процесс и контейнер не умрут. 
И докеру теперь понятно, что команду надо проитерпретировать именно башем. Можем собирать


Создадим файл `Dockerfile` (у докерфайла нет расширения):
```Dockerfile
FROM ubuntu:18.04

ENTRYPOINT ["/bin/bash", "-c", "while true; do echo fuck; sleep 2; done"]
```

- возьмем знакомую нам убунту
- укажем входную точку ENTRYPOINT. Это команда, которая будет запускаться при выполнении `doker run`
    - особенность в том, что надо передать команду и аргументы как массив 
    

    
  




## Docker FAQ

Дальше небольшой FAQ
- почему образ получился больше по размеру, чем я ожидала?
- где хранятся образы?
- latest или не latest?
- как выбрать образ из моря доступных?


### Слишком жирный Docker-образ

Докер образ во время сборки захватывает в т.н. "build context" (контекст сборки) - всю директорию в которй лежит Dockerfile.
Как правило, докерфайл кладут в корень проекта, чтобы упаковть внутрь артефакты проекта
- артефактами java/scala/go и др компилируемых языков являются исполняемые файлы. Например, jar-ки. В образ java-приложения нет смысла нести исходники 
- артефактами python/ruby/scheme приложений являются исходники.

После сборки иногда (например на "долгих" проектах) удивляются, что образ оказался на сотню-другую МБ жирнее, чем ожидалось.
Это связано как раз с мусором, попавшим в контекст сборки. 

Зачастую это содержимое папки `.git`. Можно по приколу сделать следующее - добавить в гит-репозиторий файл в 1ГБ, 
запушить, затем удалить файл и снова запушить. В репе как бы ничего нет, но в ее истории будет лежать тот гиговый файл.
Тогда следующем человеку придется клонировать 1Гб данных, хотя реальное текущее состояние проекта - 3 файлика по 10Кб :)
"Тяжеля" история может накапливаться и без больших файлов - например, за многие годы работы над проектом 

Еще неприятный момент - утащить что-то чувствуительное - например, файлик с паролями, ssh-ключами или apikey'ями.

Проблемы типично-гитовые, решение - тоже. Исопльзуется файл `.dockerfile`. [Пример такого файла](https://github.com/avbelyaev/K8S-RBAC-experiments/blob/master/.dockerignore).
Отмечу, что у `.gitignore` и `.dockerignore` немного отличается синтаксис - где-то нужны слэши, где-то нет - каждый 
раз подглядываю

**Best practice: использовать .dockerignore, чтобы в образ не утекло лишнего**


### Где хранятся образы

По аналогии с тем, как питоновские модули хранятся в pypi, java'овые артефакты хранятся в maven, docker-образы 
хранятся в docker registry, реестре (регистри) образов. Самый известный - Dockerhub - публичное хранилище докер образов.
Пока ты не зупашила туда образ, он хранится локально (`docker images`). Компании, как правило, имеют свои приватные хранилища.

![0](img/docker-registry.png)

Хотя сам докер и проприетарен (закрытое ПО), создать образ может каждый. Представь, что 1000 человек взяли за основу 
образ python, добавили сверху исходники своих программ 
- и сделали 1000 образов. Каждый примерно в 100МБ. Никакого места не хватит все это хранить - 100 ГБ. 

Так вот на самом деле значительная часть объема во всех этих образах будет одна и та же - тот самый линуск с раскатанным
поверх питоном - те самые парочка базовы слоев. Тогда хранить надо лишь 1! образ linux, 1! образ питона и 1000 папочек с исходниками.
Сколько там нынче весят исходники? Десяток килобайт? Тогда для хранения всего этого добра надо всего 10 МБ!

В этом в том числе и молниеносность пуша/пулла образов. Если у тебя на компе уже есть слой с питоном, то надо лишь
допуллить недостающее. Если на докерхабе уже есть образ линукса, надо лишь допушить недостающее. Спасибо Union FS. 

Слои (вернее их хеши) ты видишь во время пуша/пулла образа 

```
11: Pulling from library/postgres
4297e0229558: Pull complete 
bbb46d73f55c: Pull complete 
644c45c53969: Pull complete 
a4d0e23f5eaf: Extracting [=========>                                     ]  13.37MB/21.12MB
a4d0e23f5eaf: Extracting [=====================>                         ]  14.88MB/30.42MB
81bc5e1a0d35: Download complete 
78b6752b1630: Download complete 
a2e04e4389c1: Download 
```

* Слоев "между тобой и базовым" не 4 (scratch, ubuntu, python, твой), а скорее десяток, но сути это не меняет. 

По новой политике Dockerhub'а образы не востребованные в течение (кажется) 6 месяцев, удаляются. Поэтому сейчас появляется
все больше альтернативных хранилищ - Github packages (у меня в профиле есть отдельная вкладка с ним), AWS ECR и другие.


### Версионирование

Как ты знаешь, образ характериузется версией (тегом). Взять `cpython:alpine-3.8` - здесь `alpine-3.8` - тег.

Фишка докера - в **иммутабельности** образов! Это значит, образ, протегированный как `whatever:1488` всегда будет создавать
одинаковые контейнеры. 

Однако, теги можно редактировать. И под `whatever:1488`можно подложить образ с видосиком "never gonna give you up" вместо
исходников. Это считается дурной практикой и как правило запрещено правилами регистри (хотя в dockerhub так можно). 
Как описано выше, образы очень экономно расходуют место и теги можно не жалеть. 

Тэг `latest` - плавающий - он всегда указывает на самую последнюю новую версию образа. Как только выходит новая версия
образа, она помечается тегом latest. При этом в новой версии могут быть не обратносовместимые изменения (breaking changes).

Здесь все точно так же, как и с любым версионированием. На проде версия должна быть жестко зафиксирована. 
В работе, меж тем, можно использовать что угодно.

**Best practice: исопльзовать для локальной работы то же, что будет будет крутиться в проде**. Ибо дьявол кроется в деталях


### Как выбрать образ

Обычной практикой является гугление `<whatever> docker image` и, если это что-то достоано мейнстримное, 
первая ссылка будет вести на Dockerhub. Но, в случае с чем-то супер-мейнстримным, типа питона, открыв 
вкладку Tags, ты столкнешься с [52 страницами образов](https://hub.docker.com/_/python?tab=tags&page=52) (нояб 2020).
Как выбирать - непонятно.

В какой-то момент умные люди перестали это терпеть и собарли т.н. alpine-образы. 

![o](img/alpine.png)

Ты много где увидишь/услышишь слово "alpine" (альпайн, альпИн) в контексте докера. Alpine - это легковесный линукс.
В то время, как Ubuntu, Fedora, Mint, Arch и т.д. весят сотни МБ или гигабайты, Alpine,  будучи полноценным 
linux'ом, не тащит за собой мусор - ему не нужны драйвера для мышки и набор иконок - это все вырезано. 
Поэтому, он весит всего 5! (пять) мегабайт! 

Идей алпайна - избавиться от всего лишнего, таким образом облегчив образы и ускорив их старт

Вслед за alpine-linux появились и облегченные версии всех возможных технологий. "Обычный" питон может весить до 500МБ,
alpine-python весит сотню, ведь из него вырезали лишние предустановленные библиотеки, профилировщик, справки и тд. 
Обычная джава весит до гигабайта, alpine-jre весит пару сотен МБ. Гуглятся alpine-образы так же - `<whatever> alpine image`.

**Best practice: предпочитать легковесные alpine-образы обычным**

И да, `alpine-python-3.8`, `python-3.8-alpine`, `3.8alpine` и `alpine3.8` - это все еще __разные__ образы! 
Альпайны облегчили сами образы, но не процесс выбора среди других альпайнов. Раньше ты бы выбирала из океана образов, 
сейчас ты выбираешь из моря алпайн образов.

Иногда alpine может выстрлить в ногу, когда в нем не окажется библиотеки, нужной твоему модному пайспарку, 
но написанной каким-нибудь сербом в 1998 году. Я на практике такого не встречал, но это стоит иметь в виду.

А вот nano, vim, netstat, curl и даже bash в алпайне скорее всего не будет. Это все пользовательские отладочные утилиты и в
продакшене они не нужны. Их всегда можно самостоятельно добавить поверх алпайна

Возвращаясь к выбору
- образ для разработки и отладки - стандартный
- образ для продакшена - alpine
- официальный ли образ
- количество скачиваний (у мейнстримных это всего 1М+, 100М+)
- внизу обычно есть ссылка на гитхаб репо. в этой репе может лежать один голый докерфайлик на 3 строчки но зачастую
даже на такие репозитории не скупятся звездочками
- это все указано справа

![o](img/dockerhub.png)




докер жалко - на бесплатном ПО далеко не уедешь

образ скалы

docker-compose

---

# Справка

### API

**API**  - application programming interface - прикладной интерфейс разработки. 

интерфейс в терминах ООП, т.е. набор методов, видимых снаружи.
- Интерфейс холодильника - "открыть дверцу", "заркыть дверцу". 
- Интерфейс машины - "завести/остановить двигатель", "поехать вперед/назад", "повернуть направо/налево".
- Интерфейс классификатора - "fit", "predict".
Т.е. это набор команд(методов), с помощью которого можно взаимодействовать с объектом.

Так же это принято называть *"публичным контрактом"*. Контракт потому, что ты сможешь эффективно работать с объектом, 
если соблюдаешь все его условия (вызываешь с правильными аргументами, обрабатывашь ошибки и т.д.).


### REST

REST - REpresentation State Transfer - стиль архитектуры (как правило, веб приложений) для организации взаимодействия 
между клиентом и сервером. То, чем оперирует сервер назвается **ресурсами** и REST это о том, как сопоставить
документы этим ресурсам. Чисто технически - это способ проектирования API. 

Есть такое правило, что REST - это когда ты отперируешь "существительными" в организации ресурсов. 

Ты знаешь термин URL ("урл") -  - это как раз локация ресурса на просторах интернета. Ты, как пользователь
вк - всего лишь один из множества ресурсов в сети интернет, но у тебя есть идентификатор, по которому можно получить информацию о тебе,
например - `http://vk.com`

Допустим, мы делаем API для соцсети. Мы можем спроектировать API таким образом
- GET `/api/users` - список всех юзеров
- POST `/api/register` - создать пользователя
- PUT `/api/users/update?userId=123` - обновить пользователя, с ID, например, 123
- POST `/api/friends?userId=123` - получить список друзей пользователя с ID=123

такое API будет работать, но оно будет неочевидным для потребителей (другие приложения, разработчики и т.д. потребляют "API") - 
здесь присутствуют глаголы (`/register`, `/update`) и не используется богаствство протокола HTTP.

REST реализация оперирует всем, как документами:
- GET `/api/users` - список юзеров
- POST `/api/users` + json - создать нового пользователя
- GET `/api/users/<id>` - получить пользователя по ID
- PUT `/api/users/<id>`+ json - обновить информацию о пользователе
- GET `/api/users/<id>/friends` - список друзей пользователя с ID
- GET `/api/users/<id>/albums/<id>` - какой-то альбом пользователя
- DELETE `/api/users/<id>` - удалить пользователя

в данном случае мы используем иерархию, HTTP-методы и заголовки для управления докумнетами. Это более RESTful, но сама по себе
тем глубоко холиварная, т.к. нет никаких стандартов и каждый понимает как хочет.

Каждая сторка здесь указывает на конкретный документ и называется URL'ом. См [внизу](#url) 

на [хабре](https://habr.com/ru/post/483202/) можно кратко почитать про REST.


### URL

Каждый ресурс характеризуется идентификатором, называемым "урлом" (URL - Uniform Resource Locator). Например, идентификатор твоей странички ВК
уникален в рамках всего интернета! это что-то типа `https://vk.com/7846512687`. Эта строка однозначно указывает локацию документа.

![o](img/url-structure.jpg)

Откуда бы ты ни шла, ты всегда по этому URL'у найдешь только этот конкретный документ.


### HTTP

КОгда создавался интернет, достаточно было уметь передавать 1 и 0 между компьтерами по проводам. Но с развитивем интернета понадобилось 
передавать кучу сложной информации (музыка, видео) и передавать надежно (если потеряется пара кадров - не страшно, если потерять сообщение вк - страшно).

Тогда начали усложнять решение (которое изначально умело только 1 и 0 передавать) и надстраивать сверху все новые и новые протоколы. 
Так появилась модель OSI (так и называют - "модель оси") - это идеализированная модель взаимодействия систем по сети.

![o](img/osi.jpg)

В самом низу - протокол передачи 1 и 0 с помощью перемены напряежения в проводе (называется "манчестерский код").

Но как и все абстрактное в этом мире, "абстрактная модель OSI" получила реализацию в виде **"стека TCP/IP"** - он похож на слоеный пирог выше,
только в нем всего 4 уровня:

![o](img/osi-tcp.png) 
 
Так вот протокол HTTP закатывает сообщения (html'и, json'ы, картинки) в этот пирог и передает по сети. 
В этом случае говорят, что протокол HTTP использует протокол TCP, в качестве "транспорта". 

Т.е. он берет картинку, переводит ее в набор байтов, и оборачивает в HTTP запрос:
```
POST http://instagram.com/api/posts
content-type: image/jpeg
user-agent: safari/ios13
accept: text/html

<в качестве тела идут байтовое представление картинки>
```

Дальше этот текст (HTTP-запрос) бьется на куски, каждый кусок нумеруется, проставляется IP-адрес получаетеля, вычисляются хеши (чтобы онтролировать целостность) и тд.

И каждый протокол сверху вниз делает то же самое, разбивая предыдущее сообщение на меньшие части. А в самом низу наш запрос уже представлен
в бинарном виде и мы кодируем 1 и 0 в нем перепадами напряжения (или силы тока? - я не физик) в проводе.

Сервер инстаграмма эти перепады напряжения считывает и декодирует в 1 и 0 и дальше протоколы снизу вверх распаковывают сообщение и хобана - картинка передана по сети.

Теперь ты кратко, надеюсь, представляешь как работает HTTP и TCP/IP.


### Трехзвенная архитектура

aka **3-tier** architecture. приложение представляют в виде пирога из 3х слоев. 

Сверху вниз идут:
- клиентская часть (обычно в виде пользовательского GUI - graphical user interface)
- бекенд (слой с бизнес-логикой)
- уровень данных (источник данных для всего приложения)   

![o](img/tier3.jpeg)


### Виды разработки

Ознакомься сначала с [трехзвенкой](#трехзвенная-архитектура).

Разработка бывает 2х таких видов.

**Снизу-вверх** - сначала проектируют модель данных (схему бд, сущности, таблицы, ограничения и тд), потом над ней выстраивают бекенд. 
Получившийся бекенд обычно называют CRUD-бекендом (create-read-update-delete, post-get-put-delete, insert-select-update-delete) - 
то есть он предоствляет минимальный набор примитивных операций. 
Соответственно у бекенда (например, мы управляем учетками сотрудников) получается API в стиле 
- POST `/api/employees` - создать учетку
- GET `/api/employees` - получить список всех учеток
- GET `/api/employees/<id>` - получить учетку по ID
- DELETE `/api/employees/<id>` - удалить учетку
- GET `/api/access` -  получить список доступов
  
Чтобы уволить сотрудника, мы должны залистить список всех учеток, найти нужного сотрудника, достать его ID, сходить, например, в соседний API, которые заблокиурет ему доступы и передать туда ID.
Затем выполнить DELETE `/api/.../123`. Как ты понимаешь, здесь вместо сотрдников можно подставить заказ холодильника, перевод денег и что угодно.

Получается API (и само приложение), которые никакого отношения к бизнесу не имеют - такого рода проекты делают на галерах типа luxoft, айти, mc'kinsey, т.к. это делается быстрее и дешевле всего - но пользователься этим невозможно.
  
**Сверху-вниз** - разработка от потребностей пользователя. фронтенд и UX ставятся во главу угла (т.к. пользователю не продают json'ы, а продают продукт),
а дальше проектируется бекенд. Модель данных (для БД) - подстраивается под потребности пользователя и в итоге мы имеем API вида
- POST `/api/employees/<id>/deactivate` - который выполнит весь процесс по нажатию одной кнопки.

Получаем приложение в стиле Apple с одной кнопкой "сделать хорошо" - лучший UX

![o](img/scaledsimplicity.jpeg)



### Djangи Flaskи сервера

По ходу статьи я часто исолпьзую слово "сервер" или "веб-сервер" взаимозаменяемо. Но на деле все обстоит немного иначе:

- есть **приложение**: в случае Flask'а - файл `myapp.py` с набором функций (типа `@post def analyze_tone(request)`, которая принимает твои json'ы с фронта) и вызовом `app.run()` в самом низу
- есть **веб-сервер** - он просто умеет обрабатывать HTTP-запросы (и раздавать стаитику - файлики типа html/js/jss, картиночки и тд)
    - но он знать не знает о том, как вызывать приложение (питоновское, джавовое, плюсовое, наскальное, ...)
- и есть **application-server** (сервер приложений) - это товарищ, который умеет
    - принимать вызовы от веб-сервера 
    - запускать питоновский интерпретатор с приложениями (бекендами) (буквально умеет делать `python3 myapp.py`) 
    - транслирует вызовы от веб-сервера в вызовы соответствуюих функций (та самая `def analyze_tone(...)`) в файлике `myapp.py`
        - то есть из тексового HTTP-запроса создает объект класса, например, `Request`

получается, например, такая связка:
- web-server Nginx/Apache принимает HTTP-запросы и передает их app-server'у
- app-server Gunicorn принимает запросы и от веб-сервера и дергает функции твоего приложения
- функции твоего приложения принимают запросы уже в виде питоновских объяектов класса, например, `FlaskRequest extends Request` и должны вернуть объекты класса, например, `FlaskResponse` 

Ты, наверное, слышала о Django - это целая вселенная для веб-разработки на питоне. на нем можно запустить интернет-магазин за пару вечеров, но как результат он слишком перегружен и 95% его возможностей никогда не пригодятся. 
плюс, он навязывает опеределенный стиль разработки, поэтому есть "python-разработчики", а есть "django-разработчики" (точно так же java-разрабы и spring-разрабы)

Абсоютная противоположность джанге - Flask. Это крайне минималистичный фреймворк по принципу "не учите меня жить" - в нем из коробки нет ровным счетом ничего и нужно самостятельно пожключать базу данных, раздачу статики, CORS'ы и тд. 
Из-за этого он крайне хорош в образовательных целях, да и просто елси не хочешь перегружать проект ненужным хламом.

Говорят так: "Flask for the pirates, Django for the Navy" :)

Но и тот и другой из коробки несут в себе всю магию - все эти промежуточные слои с веб/application-серверами и тебе остается лишь сделать `python myapp.py`,
так что обо всех этих прослойках можно забыть, и говорить о "сервере" или "веб-сервере" как о едином компоненте.

P.S. прокси-сервер (proxy-server или просто "прокся") - это сервер, который не отвечает на запросы (как бекенд), а перенаправляет запросы куда-то дальше.

физический сервер - железка, "нарезанная" на виртуальные части, где и крутятся все описанные выше сервера. 
