# Справка


### RPC

Давным давно были камни и на камнях работала лишь одна программа. Это было задолго до интернета.
Камни умнели и превращались в компьтеры, которые могли запускать сразу 2! программы одновременно.
И в какой-то момент понадобилось организовать взаимодействие этих программ. Самый банальный пример - подключиться к принтеру
и распечатать документ (разумеется я не о PDF :) ). Тебе нужно, чтобы программа для печати (которая умеет работать с принтером)
получила на вход файлик. При этом файлик редактируется в другой программе - тектовом редакторе (в те времена - не сложнее блокнота).
Так вот, чтобы отправить файлик на печать, тебе надо как-то передать данные из одного процесса (редактора) - другому (принтеру).

В общем, когда на компьютерах стало возможным запускать более одной 
программы одновременно, потребовалось организовать **межпроцессное взаимодействие** (inter-process communication).

Его организовали. Если в двух словах, то поскольку все программы жили в одном адресном пространстве, то передача данных
это по сути запись их по определенному адресу (0x123456) и передача этого адреса и размера данных другому процессу.
После чего этот второй - читает заданные 64 килобайта начиная с 0x123456 и собственно, получает доступ к данным.  
 
И жили они долго и счастливо... пока не появился интернет.

Интернет разделил компьютеры. Теперь у тебя уже мог быть т.н. сетевой принтер и доступ к нему из разных терминалов 
(компьтеров). Или если ты работаешь в НИИ, то у вас есть компьютер размером с комнату, которому надо отправить 
данные на обработку. Суть в том, что физически компьютеры находятся в разных местах. 

Межпроцессное взаимодействие, как ты понимаешь не работало - данные находятся в разных адресных пространствах. То есть,
если ты скажем принтеру "прочитай и распечатай файлик из 0x123456", то в его адресном пространстве там будут рандомные данные.

Понадобилось организовать взаимодействие процессов по сети. И его организовали, назвав это удаленный вызов процедур 
(RPC, "арписи" - **Remote procedure call**). Идейно все было очень просто:
- есть машины А и Б которые взаимодействуют по сети
- твой код выполняется на машине А.
- вот он в какой-то момент взызывает функцию... выполнение которой происходит на машине Б
- управление и результат возвращаются тебе на машину А
- программа продолжается

В общем суть в том, что взаимодействие происходит прозрачно для тебя, как для программиста: 
Программы на А и Б никак не взаимодействуют напрямую! Ха!

Вместо этого, и на клиенте и на сервере есть т.н.называемые **заглушки** (stub). Клиентская заглушка это такая функция, 
которая застваляет твою программу на А думать, что программа Б работает **локально**. 
В свою очередь, ответная серверная заглушка заставляет программу Б думать, что ее вызвали локально.

То есть ни та, ни та стороны не догадываются что между ними сеть. Чтобы не запутать, вот как это выглядело бы в коде:

рассмотрим код A (клиента):
```
// твоя программа
func myAwesomeFunc() {
   x = 1, y = 2 
   result = foo(x, y)
   ...
}

// не твоя программа
func foo(x, y) {
    // функция foo на самом деле содержит клиенсткую заглушку  
    clientStub() {
        sendRequestToServerStub(args)
        result = waitForAnswer()
    }
    return result 
}
```

- в своем коде ты просто вызываешь foo. реальное устройство функции `foo` скрыто от тебя, как программиста.
- функция foo на самом деле пустышка - она просто заставляет твою программу думать, что вызов foo происходит дольше обычного
- внутри же она пересылает данные на сервер и ожидает ответ

рассмторим Б (сервер):
```
// севрерная заглушка 
func serverStub() {
    args = waitForIncomingRequest()
    result = foo(args)
    sendBack(result)
}

// реально работающся функция foo
func foo(x, y) {
    return x + y;
}
```

- на сервере определена и работает функция foo. Но она не догадывается, что код, вызвавший ее находится на другой машине.
- она работает так, как если бы ее вызвали отсюда же.
- как только foo отработала, серверная заглушка забирает результат, грузит его и передает на клиент
- твоя программа продолжает работать, как будто ничего не произошло

![o](img/rpc.gif)

В общем вся суть именно в **блаженном неведении** ни одной ни другой стороны, т.к. реально взаимодействующий код
находится где-то в глубине библиотечных функций.

Идея проста, но сразу возникают вопросы. Например, самое первое - способ передачи аргументов. Ты знаешь плюсы лучше меня, 
и знаешь, что он бывает по ссылке `foo(&data)` и по значению `foo(data)`. Во втором случае данные копируются (то есть дублируются) и передаются вызываемой функции.
В первом - передается лишь ссылка на данные, реально данные остаются там же где и были.

И вот первая же проблема RPC - ты не можешь передать программе Б адрес данных на машине А - у них абсолютно разные адресные пространства.
То есть заглушки (обе, они ведь "симметричные") должны поумнеть и понять, что в реальности надо не просто передать
адрес, а 
- прочитать данные на машине А по адресу 0x123456, передать их по сети
- разложить их на машине Б
- сообщить функции foo (ведь она принимает имеено ссылку) их адрес уже на машине Б
- посокльку передача по ссылке предполагает, что ты работаешь не с копией а с оригинльными данными, то
- по завершению foo надо вернуть не толкьо результат, но еще и ту часть данных, что отредактировала foo
- передать по сети 
- заменить устаревшие данные на машине А, чтобы они вновь лежали по адресу 0x123456

Как видишь, уже сложнее.

В какой-то момент инженеры Sun (те самые, что придумали java), сформулировали заблуждения о работе сети. Вставлю картинкой

![o](img/fallacies.png)

Применительно к нашей теме, заглушки теперь должны уметь
- обрабатывать ошибки
- распеределять нагрузку
- защищать данные
- и еще много чего

То есть заглушки становятся сложнее программы. А если мы сюда еше и бизнес логику добавим (например, в случае 404 показывать
пользователю картинку), то мы уже не сможем прозрачно для кода сказать, что "вот такие ошибки обрабатывай а это не обрабатывай".

Зачем нам тогда вообще заглушка, если у нас "абстракция протекает"? (abstraction/logic leak - 
это когда ты отгородился от чего-то то низкоуровневого и __почти__ забыл, что оно существует, но логика неприкаянная:
ты работаешь с интерфейсом "холдильник" по принципу "открыть дверцу, достать/положить продукты, закрыть дверцу", но холодильник надо еще и 
размораживать иногда. но ведь он был создан, чтобы ты думал о продуктах, а не о нем. но абстракция протекла и ты знаешь о внутреннем устройстве холодильника).
Так вот и здесь ты отгородился от сети, но она периодически напоминает о себе, хотя должна быть скрыта под слоем rpc'шных либ.

...

Наши дни:
```python
def myAwesomeFunc():
    do:
        response = requests.post("server.com/foo", 
                            json={"x": 1, "y": 2}, 
                            headers={"Authorization: Basic aS1rbmV3LXlvdS1hcmUtY3VyaW91cyEgLW4K"})
        if 404 == response.status:
            return 'not-the-page-you-are-looking-for.png'
    while response.status != 200
    ...
``` 

Люди перестали скрывать, что программы взаимодействуют по сети - они теперь сами контролирую, как происходят удаленные вызовы.
Плата за это - в код просочились все кишки HTTP.

Так вот, RPC'шный подход как бы умер, но гугл решил его возродить в виде google RPC - gRPC. С чем это связано я не знаю,
но могу предположить, что с объемыми гугловых кодовых баз, расходы на утилитарный код (все эти ретраи, заголовки, сериализация
в джосны) превысили расходы на бизнес-логику. И они решили вновь "скрыть сеть". У них есть свой язык описания заглушек,
из которых генерятся эти самые client-stub и server-stub для любого языка (банальные Java-классы с getter'ами и сеттерами, питонячьи классы, сишные структуры и тд.). 

gRPC это чисто технический аспект реализации API. Плата за использование - потеря контроля.

Бенефиты от использования gRPC можно получить на многомилионной кодовой базе. 
зачем gRPC средней или даже большой компании (при условии что фаанги - огромные) - мне непонятно.
Но дальше фаанга это не особенно ушло, насколько я знаю.
 
И, с трендом на усложнение всего, честно говоря, сомневаюсь, что мы сможем вернуться в то "беззаботное время" 
(хехе, мы тогда еще не даже родились), когда компьютеры были едины.


P.S.  
Знать почему мы пишем ретраи в коде и обрабатываем HTTP-статусы - однозначно надо. я попытался это кратко объяснить выше, как люди пришли к этому.
Уметь генерить заглушки самому - ну такое - не понятно где применить этот навык.
На кой черт это надо _уметь_ еще и дата-саентистам - вообще непонятно, ибо редкий разраб имеет опыт именно генерации 
этого всего - очень уж нисшевая технология


### API

**API**  - application programming interface - прикладной интерфейс разработки. 

интерфейс в терминах ООП, т.е. набор методов, видимых снаружи.
- Интерфейс холодильника - "открыть дверцу", "заркыть дверцу". 
- Интерфейс машины - "завести/остановить двигатель", "поехать вперед/назад", "повернуть направо/налево".
- Интерфейс классификатора - "fit", "predict".
Т.е. это набор команд(методов), с помощью которого можно взаимодействовать с объектом.

Так же это принято называть *"публичным контрактом"*. Контракт потому, что ты сможешь эффективно работать с объектом, 
если соблюдаешь все его условия (вызываешь с правильными аргументами, обрабатывашь ошибки и т.д.).


### Трехзвенная архитектура

aka **3-tier** architecture. приложение представляют в виде пирога из 3х слоев. 

Сверху вниз идут:
- клиентская часть (обычно в виде пользовательского GUI - graphical user interface)
- бекенд (слой с бизнес-логикой)
- уровень данных (источник данных для всего приложения)   

![o](img/tier3.jpeg)


### Виды разработки

Ознакомься сначала с [трехзвенкой](#трехзвенная-архитектура).

Разработка бывает 2х таких видов.

**Снизу-вверх** - сначала проектируют модель данных (схему бд, сущности, таблицы, ограничения и тд), потом над ней выстраивают бекенд. 
Получившийся бекенд обычно называют CRUD-бекендом (create-read-update-delete, post-get-put-delete, insert-select-update-delete) - 
то есть он предоствляет минимальный набор примитивных операций. 

Соответственно у бекенда (например, мы управляем учетками сотрудников) получается API в стиле 
- POST `/api/employees` - создать учетку
- GET `/api/employees` - получить список всех учеток
- GET `/api/employees/<id>` - получить учетку по ID
- DELETE `/api/employees/<id>` - удалить учетку
- GET `/api/access` -  получить список доступов
  
Чтобы уволить сотрудника, мы должны залистить список всех учеток, найти нужного сотрудника, достать его ID, сходить, например, в соседний API, которые заблокиурет ему доступы и передать туда ID.
Затем выполнить DELETE `/api/.../123`. Как ты понимаешь, здесь вместо сотрдников можно подставить заказ холодильника, перевод денег и что угодно.

Получается API (и само приложение), которые никакого отношения к бизнесу не имеют - такого рода проекты делают на галерах типа luxoft, айти, mc'kinsey, т.к. это делается быстрее и дешевле всего - но пользователься этим невозможно.
  
**Сверху-вниз** - разработка от потребностей пользователя. фронтенд и UX ставятся во главу угла (т.к. пользователю не продают json'ы, а продают продукт),
а дальше проектируется бекенд. Модель данных (для БД) - подстраивается под потребности пользователя и в итоге мы имеем API вида
- POST `/api/employees/<id>/deactivate` - который выполнит весь процесс по нажатию одной кнопки.

Получаем приложение в стиле Apple с одной кнопкой "сделать хорошо" - лучший UX

![o](img/scaledsimplicity.jpeg)



### REST

REST - REpresentation State Transfer - стиль архитектуры (как правило, веб приложений) для организации взаимодействия 
между клиентом и сервером. То, чем оперирует сервер назвается **ресурсами** и REST это о том, как сопоставить
документы этим ресурсам. Чисто технически - это способ проектирования API. 

Есть такое правило, что REST - это когда ты отперируешь "существительными" в организации ресурсов. 

Ты знаешь термин URL ("урл") -  - это как раз локация ресурса на просторах интернета. Ты, как пользователь
вк - всего лишь один из множества ресурсов в сети интернет, но у тебя есть идентификатор (ID вкнотакте), 
по которому можно получить информацию о тебе на `http://vk.com`

Допустим, мы делаем API для соцсети. Мы можем спроектировать API таким образом
- GET `/api/users` - список всех юзеров
- POST `/api/register` - создать пользователя
- PUT `/api/users/update?userId=123` - обновить пользователя, с ID, например, 123
- POST `/api/friends?userId=123` - получить список друзей пользователя с ID=123

такое API будет работать, но оно будет неочевидным для потребителей (другие приложения, разработчики и т.д. потребляют "API") - 
здесь присутствуют глаголы (`/register`, `/update`) и не используется "богаствство HTTP" (методы, заголовки, коды).

REST оперирует пользователями как документами:
- GET `/api/users` - список юзеров
- POST `/api/users` + json - создать нового пользователя
- GET `/api/users/<id>` - получить пользователя по ID
- PUT `/api/users/<id>`+ json - обновить информацию о пользователе
- GET `/api/users/<id>/friends` - список друзей пользователя с ID
- GET `/api/users/<id>/albums/<id>` - какой-то альбом пользователя
- DELETE `/api/users/<id>` - удалить пользователя

в данном случае мы используем иерархию, HTTP-методы и заголовки для управления докумнетами. 
Это более RESTful, но сама по себе тема глубоко холиварная, т.к. нет никаких стандартов и каждый понимает как хочет.

Каждая сторка здесь указывает на конкретный документ и называется URL'ом. См [внизу](#url) 

на [хабре](https://habr.com/ru/post/483202/) можно кратко почитать про REST.
 


### URL

Каждый ресурс характеризуется идентификатором, называемым "урлом" (URL - Uniform Resource Locator). Например, идентификатор твоей странички ВК
уникален в рамках всего интернета! это что-то типа `https://vk.com/7846512687`. Эта строка однозначно указывает локацию документа.

![o](img/url-structure.jpg)

Откуда бы ты ни шла, ты всегда по этому URL'у найдешь только этот конкретный документ.


### HTTP

КОгда создавался интернет, достаточно было уметь передавать 1 и 0 между компьтерами по проводам. Но с развитивем интернета понадобилось 
передавать кучу сложной информации (музыка, видео) и передавать надежно (если потеряется пара кадров - не страшно, если потерять сообщение вк - страшно).

Тогда начали усложнять решение (которое изначально умело только 1 и 0 передавать) и надстраивать сверху все новые и новые протоколы. 
Так появилась модель OSI (так и называют - "модель оси") - это идеализированная модель взаимодействия систем по сети.

![o](img/osi.jpg)

В самом низу - протокол передачи 1 и 0 с помощью перемены напряежения в проводе (называется "манчестерский код").

Но как и все абстрактное в этом мире, "абстрактная модель OSI" получила реализацию в виде **"стека TCP/IP"** - он похож на слоеный пирог выше,
только в нем всего 4 уровня:

![o](img/osi-tcp.png) 
 
Так вот протокол HTTP закатывает сообщения (html'и, json'ы, картинки) в этот пирог и передает по сети. 
В этом случае говорят, что протокол HTTP использует протокол TCP, в качестве "транспорта". 

Т.е. он берет картинку, переводит ее в набор байтов, и оборачивает в HTTP запрос:
```
POST http://instagram.com/api/posts
content-type: image/jpeg
user-agent: safari/ios13
accept: text/html

<в качестве тела идут байтовое представление картинки>
```

Дальше этот текст (HTTP-запрос) бьется на куски, каждый кусок нумеруется, проставляется IP-адрес получаетеля, вычисляются хеши (чтобы онтролировать целостность) и тд.

И каждый протокол сверху вниз делает то же самое, разбивая предыдущее сообщение на меньшие части. А в самом низу наш запрос уже представлен
в бинарном виде и мы кодируем 1 и 0 в нем перепадами напряжения (или силы тока? - я не физик) в проводе.

Сервер инстаграмма эти перепады напряжения считывает и декодирует в 1 и 0 и дальше протоколы снизу вверх распаковывают сообщение и хобана - картинка передана по сети.

Теперь ты кратко, надеюсь, представляешь как работает HTTP и TCP/IP.





### Django-Flask

По ходу статьи я часто исолпьзую слово "сервер" или "веб-сервер" взаимозаменяемо. Но на деле все обстоит немного иначе:

- есть **приложение**: в случае Flask'а - файл `myapp.py` с набором функций (типа `@post def analyze_tone(request)`, которая принимает твои json'ы с фронта) и вызовом `app.run()` в самом низу
- есть **веб-сервер** - он просто умеет обрабатывать HTTP-запросы (и раздавать стаитику - файлики типа html/js/jss, картиночки и тд)
    - но он знать не знает о том, как вызывать приложение (питоновское, джавовое, плюсовое, наскальное, ...)
- и есть **application-server** (сервер приложений) - это товарищ, который умеет
    - принимать вызовы от веб-сервера 
    - запускать питоновский интерпретатор с приложениями (бекендами) (буквально умеет делать `python3 myapp.py`) 
    - транслирует вызовы от веб-сервера в вызовы соответствуюих функций (та самая `def analyze_tone(...)`) в файлике `myapp.py`
        - то есть из тексового HTTP-запроса создает объект класса, например, `Request`

получается, например, такая связка:
- web-server Nginx/Apache принимает HTTP-запросы и передает их app-server'у
- app-server Gunicorn принимает запросы и от веб-сервера и дергает функции твоего приложения
- функции твоего приложения принимают запросы уже в виде питоновских объяектов класса, например, `FlaskRequest extends Request` и должны вернуть объекты класса, например, `FlaskResponse` 

Ты, наверное, слышала о Django - это целая вселенная для веб-разработки на питоне. на нем можно запустить интернет-магазин за пару вечеров, но как результат он слишком перегружен и 95% его возможностей никогда не пригодятся. 
плюс, он навязывает опеределенный стиль разработки, поэтому есть "python-разработчики", а есть "django-разработчики" (точно так же java-разрабы и spring-разрабы)

Абсоютная противоположность джанге - Flask. Это крайне минималистичный фреймворк по принципу "не учите меня жить" - в нем из коробки нет ровным счетом ничего и нужно самостятельно пожключать базу данных, раздачу статики, CORS'ы и тд. 
Из-за этого он крайне хорош в образовательных целях, да и просто елси не хочешь перегружать проект ненужным хламом.

Говорят так: "Flask for the pirates, Django for the Navy" :)

Но и тот и другой из коробки несут в себе всю магию - все эти промежуточные слои с веб/application-серверами и тебе остается лишь сделать `python myapp.py`,
так что обо всех этих прослойках можно забыть, и говорить о "сервере" или "веб-сервере" как о едином компоненте.

P.S. прокси-сервер (proxy-server или просто "прокся") - это сервер, который не отвечает на запросы (как бекенд), а перенаправляет запросы куда-то дальше.

физический сервер - железка, "нарезанная" на виртуальные части, где и крутятся все описанные выше сервера. 
